# Architecture Diagrams

## System Overview

```mermaid
graph TB
    User[ğŸ‘¤ User] --> UI[ğŸ¨ React Frontend]
    UI --> Nginx[ğŸ”€ Nginx Reverse Proxy]
    Nginx --> API[ğŸš€ FastAPI Backend]
    
    API --> LLM[ğŸ¤– LLM Service]
    LLM --> AzureAI[ğŸ¢ Azure OpenAI]
    LLM --> OpenAI[ğŸ§  OpenAI GPT-4]
    LLM --> Anthropic[ğŸ­ Anthropic Claude]
    
    API --> Monitor[ğŸ“Š Monitoring Connectors]
    Monitor --> Grafana[ğŸ“ˆ Grafana]
    Monitor --> Prometheus[ğŸ“Š Prometheus] 
    Monitor --> Elastic[ğŸ” Elasticsearch]
    Monitor --> Nagios[âš ï¸ Nagios]
    
    API --> Memory[ğŸ’¾ Conversation Memory]
    API --> Analyzer[ğŸ” Incident Analyzer]
    
    style User fill:#e1f5fe
    style LLM fill:#f3e5f5
    style AzureAI fill:#0078d4,color:#fff
    style Monitor fill:#e8f5e8
```

## Request Flow Architecture

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant F as ğŸ¨ Frontend
    participant N as ğŸ”€ Nginx
    participant A as ğŸš€ API
    participant L as ğŸ¤– LLM Service
    participant M as ğŸ“Š Monitoring
    participant DB as ğŸ’¾ Memory
    
    U->>F: Ask question
    F->>N: HTTP Request
    N->>A: Forward to API
    
    A->>DB: Store user message
    A->>M: Query monitoring data
    M-->>A: Return alerts/metrics
    
    A->>A: Analyze query complexity
    
    alt Complex Query (AI)
        A->>L: Generate AI response
        L->>L: Create incident context
        L-->>A: Intelligent analysis
    else Simple Query (Traditional)
        A->>A: Rule-based response
    end
    
    A->>DB: Store response
    A-->>N: Return response
    N-->>F: Forward response
    F-->>U: Display result
```

## LLM Integration Flow

```mermaid
flowchart TD
    Start([ğŸš€ User Query]) --> Parse[ğŸ“ Parse Query]
    Parse --> Complex{ğŸ¤” Complex Query?}
    
    Complex -->|Yes| LLM_Available{ğŸ¤– LLM Available?}
    Complex -->|No| Traditional[ğŸ“Š Traditional Response]
    
    LLM_Available -->|Yes| Context[ğŸ“‹ Create Context]
    LLM_Available -->|No| Traditional
    
    Context --> History[ğŸ’­ Get Conversation History]
    History --> Provider{ğŸ”€ Choose Provider}
    
    Provider -->|Azure OpenAI| AzureGPT[ğŸ¢ Azure GPT-4 Analysis]
    Provider -->|OpenAI| GPT[ğŸ§  GPT-4 Analysis]
    Provider -->|Anthropic| Claude[ğŸ­ Claude Analysis]
    Provider -->|Fallback| Traditional
    
    AzureGPT --> Response[ğŸ“¤ AI Response]
    
    GPT --> Response[ğŸ“¤ AI Response]
    Claude --> Response
    Traditional --> Response
    
    Response --> Memory[ğŸ’¾ Save to Memory]
    Memory --> User([ğŸ‘¤ Return to User])
    
    style Start fill:#e3f2fd
    style LLM_Available fill:#f3e5f5
    style Response fill:#e8f5e8
    style User fill:#fff3e0
```

## Docker Architecture

```mermaid
graph TB
    subgraph "ğŸ³ Docker Environment"
        subgraph "ğŸŒ Network: chatbot-network"
            N[ğŸ”€ Nginx Container<br/>:80, :443]
            F[âš›ï¸ Frontend Container<br/>:3000]
            B[ğŸš€ Backend Container<br/>:8000]
        end
        
        subgraph "ğŸ“ Volumes"
            V1[nginx-logs]
            V2[SSL Certificates]
        end
    end
    
    subgraph "ğŸŒ External Services"
        LLM_EXT[ğŸ¤– LLM APIs<br/>Azure OpenAI/OpenAI/Anthropic]
        MON_EXT[ğŸ“Š Monitoring<br/>Grafana/Prometheus/etc]
    end
    
    Client[ğŸ’» Client] --> N
    N --> F
    N --> B
    B --> LLM_EXT
    B --> MON_EXT
    
    N -.-> V1
    N -.-> V2
    
    style N fill:#ff9800,color:#fff
    style F fill:#2196f3,color:#fff
    style B fill:#4caf50,color:#fff
```

## File Structure Diagram

```mermaid
graph TD
    Root[ğŸ“ chatter/] --> Backend[ğŸ“ backend/]
    Root --> Frontend[ğŸ“ frontend/]
    Root --> Docker[ğŸ“ docker configs]
    Root --> Docs[ğŸ“ docs/]
    Root --> Scripts[ğŸ“ scripts/]
    Root --> Nginx[ğŸ“ nginx/]
    
    Backend --> MainPy[ğŸ main.py<br/>FastAPI App]
    Backend --> LLMPy[ğŸ¤– llm_service.py<br/>AI Integration]
    Backend --> ConnDir[ğŸ“ connectors/]
    Backend --> ConfigPy[âš™ï¸ config.py]
    Backend --> ReqTxt[ğŸ“‹ requirements.txt]
    Backend --> DockerfileB[ğŸ³ Dockerfile]
    
    ConnDir --> BasePy[ğŸ”Œ base.py<br/>Base Connector]
    ConnDir --> ElasticPy[ğŸ” elasticsearch.py<br/>ES Connector]
    
    Frontend --> SrcDir[ğŸ“ src/]
    Frontend --> PackageJson[ğŸ“¦ package.json]
    Frontend --> DockerfileF[ğŸ³ Dockerfile]
    Frontend --> IndexHtml[ğŸ“„ index.html]
    
    SrcDir --> AppTsx[âš›ï¸ App.tsx<br/>Main Component]
    SrcDir --> MainTsx[ğŸš€ main.tsx<br/>Entry Point]
    SrcDir --> IndexCss[ğŸ¨ index.css<br/>Styles]
    
    Docker --> ComposeYml[ğŸ³ docker-compose.yml]
    Docker --> ComposeOverride[ğŸ”§ docker-compose.override.yml]
    Docker --> ComposeProd[ğŸš€ docker-compose.prod.yml]
    Docker --> EnvExample[âš™ï¸ .env.example]
    
    Nginx --> NginxConf[ğŸ”€ nginx.conf<br/>Reverse Proxy]
    Nginx --> SSL[ğŸ”’ ssl/<br/>Certificates]
    
    Scripts --> Setup[âš¡ setup.sh<br/>Auto Setup]
    
    Docs --> Architecture[ğŸ“Š architecture-diagrams.md]
    Docs --> DockerMd[ğŸ³ DOCKER.md]
    
    Root --> ReadmeMd[ğŸ“š README.md]
    
    style Root fill:#e3f2fd
    style Backend fill:#4caf50,color:#fff
    style Frontend fill:#2196f3,color:#fff
    style LLMPy fill:#f3e5f5
```

## Data Flow Diagram

```mermaid
flowchart LR
    subgraph "ğŸ“Š Monitoring Sources"
        G[ğŸ“ˆ Grafana]
        P[ğŸ“Š Prometheus]
        E[ğŸ” Elasticsearch]
        N[âš ï¸ Nagios]
    end
    
    subgraph "ğŸ”„ Processing Layer"
        C[ğŸ”Œ Connectors]
        A[ğŸ” Analyzer]
        L[ğŸ¤– LLM Service]
    end
    
    subgraph "ğŸ’¾ Storage Layer"
        M[ğŸ’­ Memory]
        H[ğŸ“š History]
    end
    
    subgraph "ğŸ¯ Output Layer"
        AI[ğŸ¤– AI Response]
        TR[ğŸ“Š Traditional Response]
        S[ğŸ’¡ Suggestions]
    end
    
    G --> C
    P --> C
    E --> C
    N --> C
    
    C --> A
    A --> L
    
    L --> M
    M --> H
    
    L --> AI
    A --> TR
    AI --> S
    TR --> S
    
    style G fill:#ff9800
    style P fill:#e91e63
    style E fill:#3f51b5
    style N fill:#f44336
    style L fill:#9c27b0
    style AI fill:#4caf50
```

## Conversation Flow

```mermaid
stateDiagram-v2
    [*] --> NewChat: User starts chat
    
    NewChat --> ProcessQuery: User sends message
    ProcessQuery --> QueryAnalysis: Analyze query type
    
    QueryAnalysis --> SimpleQuery: Simple data request
    QueryAnalysis --> ComplexQuery: Complex analysis needed
    
    SimpleQuery --> MonitoringData: Fetch monitoring data
    MonitoringData --> TraditionalResponse: Generate response
    
    ComplexQuery --> LLMCheck: Check LLM availability
    LLMCheck --> LLMProcess: LLM available
    LLMCheck --> TraditionalResponse: No LLM, fallback
    
    LLMProcess --> ContextBuild: Build incident context
    ContextBuild --> HistoryRetrieval: Get conversation history
    HistoryRetrieval --> AIGeneration: Generate AI response
    
    AIGeneration --> ResponseReady: AI response generated
    TraditionalResponse --> ResponseReady: Traditional response ready
    
    ResponseReady --> SaveMemory: Save to conversation memory
    SaveMemory --> SendResponse: Send to user
    
    SendResponse --> WaitingForInput: Waiting for next message
    WaitingForInput --> ProcessQuery: User sends another message
    WaitingForInput --> [*]: Chat ends
```

## Component Architecture

```mermaid
graph TB
    subgraph "ğŸ¨ Frontend Components"
        App[ğŸ“± App.tsx<br/>Main Chat Interface]
        Chat[ğŸ’¬ Chat Component]
        Message[ğŸ’Œ Message Component]
        Input[âŒ¨ï¸ Input Component]
        Suggestions[ğŸ’¡ Suggestions Component]
    end
    
    subgraph "ğŸš€ Backend Services"
        FastAPI[ğŸ”¥ FastAPI Router]
        ChatEndpoint[ğŸ’¬ /chat endpoint]
        HealthEndpoint[â¤ï¸ /health endpoint]
        LLMService[ğŸ¤– LLM Service]
        IncidentAnalyzer[ğŸ” Incident Analyzer]
        Connectors[ğŸ”Œ Monitoring Connectors]
    end
    
    subgraph "ğŸ¤– AI Layer"
        AzureClient[ğŸ¢ Azure OpenAI Client]
        OpenAIClient[ğŸ§  OpenAI Client]
        AnthropicClient[ğŸ­ Anthropic Client]
        PromptEngine[ğŸ“ Prompt Engine]
        TokenManager[ğŸ« Token Manager]
    end
    
    subgraph "ğŸ’¾ Data Layer"
        ConversationMemory[ğŸ’­ Conversation Memory]
        IncidentContext[ğŸ“‹ Incident Context]
        MonitoringData[ğŸ“Š Monitoring Data]
    end
    
    App --> Chat
    Chat --> Message
    Chat --> Input
    Chat --> Suggestions
    
    Chat --> FastAPI
    FastAPI --> ChatEndpoint
    FastAPI --> HealthEndpoint
    
    ChatEndpoint --> LLMService
    ChatEndpoint --> IncidentAnalyzer
    ChatEndpoint --> ConversationMemory
    
    LLMService --> AzureClient
    LLMService --> OpenAIClient
    LLMService --> AnthropicClient
    LLMService --> PromptEngine
    LLMService --> TokenManager
    
    IncidentAnalyzer --> Connectors
    Connectors --> MonitoringData
    
    LLMService --> IncidentContext
    IncidentContext --> MonitoringData
    
    style App fill:#2196f3,color:#fff
    style LLMService fill:#9c27b0,color:#fff
    style AzureClient fill:#0078d4,color:#fff
    style OpenAIClient fill:#00c853,color:#fff
    style AnthropicClient fill:#ff6d00,color:#fff
```

## Deployment Architecture

```mermaid
graph TB
    subgraph "ğŸŒ Production Environment"
        LB[âš–ï¸ Load Balancer<br/>nginx]
        
        subgraph "ğŸ”„ Application Tier"
            F1[âš›ï¸ Frontend 1]
            F2[âš›ï¸ Frontend 2]
            B1[ğŸš€ Backend 1]
            B2[ğŸš€ Backend 2]
            B3[ğŸš€ Backend 3]
        end
        
        subgraph "ğŸ“Š Monitoring Tier"
            G[ğŸ“ˆ Grafana]
            P[ğŸ“Š Prometheus]
            E[ğŸ” Elasticsearch]
            N[âš ï¸ Nagios]
        end
        
        subgraph "ğŸ¤– External AI Services"
            AzureOpenAI[ğŸ¢ Azure OpenAI]
            OpenAI[ğŸ§  OpenAI API]
            Anthropic[ğŸ­ Anthropic API]
        end
    end
    
    Users[ğŸ‘¥ Users] --> LB
    LB --> F1
    LB --> F2
    LB --> B1
    LB --> B2
    LB --> B3
    
    B1 --> G
    B1 --> P
    B1 --> E
    B1 --> N
    B2 --> G
    B2 --> P
    B2 --> E
    B2 --> N
    B3 --> G
    B3 --> P
    B3 --> E
    B3 --> N
    
    B1 --> AzureOpenAI
    B1 --> OpenAI
    B1 --> Anthropic
    B2 --> AzureOpenAI
    B2 --> OpenAI
    B2 --> Anthropic
    B3 --> AzureOpenAI
    B3 --> OpenAI
    B3 --> Anthropic
    
    style LB fill:#ff9800,color:#fff
    style AzureOpenAI fill:#0078d4,color:#fff
    style OpenAI fill:#00c853,color:#fff
    style Anthropic fill:#ff6d00,color:#fff
```